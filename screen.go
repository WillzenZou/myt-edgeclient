// main.go
package main

/*
#cgo pkg-config: libavcodec libavutil libswscale libswresample
#cgo CFLAGS: -IE:\MYT\mytrpa\include
#cgo LDFLAGS: -L${SRCDIR} -lmytrpc
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <sys/time.h>
#include "libmytrpc.h"

//static void (*onVideoStream)(int rot,void* data,int len);
//static void(*onAudioStream)(void* data, int len);

// å£°æ˜å›è°ƒå‡½æ•°ï¼Œç”± Go å®ç°
extern void videoStreamCallback(int rot, void* data, int len);
// extern void audioStreamCallback(void* data, int len);

extern void addaudio();

#include <libavcodec/avcodec.h>
#include <libavutil/imgutils.h>
#include <libswscale/swscale.h>
#include <libavutil/channel_layout.h>
#include <pthread.h>
typedef struct {
    AVCodecContext *codec_ctx;
    AVFrame *frame;
    struct SwsContext *sws_ctx;
    uint8_t *buffer;
    int width;
    int height;
    int sws_src_format;
    AVBufferRef *hw_device_ctx;
} Decoder;

// ç¡¬ä»¶è§£ç å™¨ç±»å‹ä¼˜å…ˆçº§é…ç½®
static const enum AVHWDeviceType hw_priority[] = {
    AV_HWDEVICE_TYPE_D3D12VA,
    AV_HWDEVICE_TYPE_D3D11VA,    // Windows Direct3D 11
    AV_HWDEVICE_TYPE_DXVA2,      // Windows DirectX Video Acceleration
    AV_HWDEVICE_TYPE_CUDA,       // NVIDIA CUDA
    AV_HWDEVICE_TYPE_QSV,        // Intel Quick Sync
    AV_HWDEVICE_TYPE_AMF,        // AMD AMF
    AV_HWDEVICE_TYPE_VULKAN,
    AV_HWDEVICE_TYPE_VAAPI,
    AV_HWDEVICE_TYPE_VDPAU,
    AV_HWDEVICE_TYPE_NONE        // è½¯ä»¶å›é€€
};

// æ·»åŠ éŸ³é¢‘é˜Ÿåˆ—ç›¸å…³å®šä¹‰
#define AUDIO_QUEUE_SIZE 50
typedef struct {
    uint8_t *data;
    int size;
} AudioPacket;

static AudioPacket audio_packet_queue[AUDIO_QUEUE_SIZE];
static int audio_queue_head = 0;
static int audio_queue_tail = 0;
static pthread_mutex_t audio_queue_mutex = PTHREAD_MUTEX_INITIALIZER;
static pthread_cond_t audio_queue_cond = PTHREAD_COND_INITIALIZER;
static volatile int audio_processing = 0;


static Decoder* create_decoder() {
    // æ”¯æŒçš„ç¡¬ä»¶è§£ç å™¨ä¼˜å…ˆçº§åˆ—è¡¨
    const char *hw_decoders[] = {
        "h264_d3d12va", // D3D11 Video Acceleration
        "h264_d3d11va", // D3D11 Video Acceleration
        //"h264_cuvid",   // NVIDIA CUVID
        //"h264_qsv",     // Intel QSV
        //"h264_amf",     // AMD AMF
        NULL            // æœ€åå°è¯•è½¯è§£
    };

    const AVCodec *codec = NULL;
    AVBufferRef *hw_device_ctx = NULL;
    AVCodecContext *codec_ctx = NULL;
    Decoder *d = NULL;

    // å°è¯•ç¡¬ä»¶è§£ç å™¨
    for (int i = 0; hw_decoders[i]; i++) {
        codec = avcodec_find_decoder_by_name(hw_decoders[i]);
        if (!codec) continue;

        enum AVHWDeviceType type = AV_HWDEVICE_TYPE_NONE;
        if (strstr(hw_decoders[i], "cuvid")) type = AV_HWDEVICE_TYPE_CUDA;
        else if (strstr(hw_decoders[i], "qsv")) type = AV_HWDEVICE_TYPE_QSV;
        else if (strstr(hw_decoders[i], "d3d11va")) type = AV_HWDEVICE_TYPE_D3D11VA;
        else if (strstr(hw_decoders[i], "d3d12va")) type = AV_HWDEVICE_TYPE_D3D12VA;
        else if (strstr(hw_decoders[i], "amf")) type = AV_HWDEVICE_TYPE_D3D11VA;

        if (av_hwdevice_ctx_create(&hw_device_ctx, type, NULL, NULL, 0) < 0) {
            hw_device_ctx = NULL;
            continue;
        }

        codec_ctx = avcodec_alloc_context3(codec);
        if (!codec_ctx) continue;

		codec_ctx->pkt_timebase = (AVRational){1, 1000};

        codec_ctx->hw_device_ctx = av_buffer_ref(hw_device_ctx);
        if (avcodec_open2(codec_ctx, codec, NULL) == 0) break;

        avcodec_free_context(&codec_ctx);
        av_buffer_unref(&hw_device_ctx);
    }

    // å›é€€åˆ°è½¯è§£
    if (!codec_ctx) {
        codec = avcodec_find_decoder(AV_CODEC_ID_H264);
        if (!codec) return NULL;
        
        codec_ctx = avcodec_alloc_context3(codec);
        if (!codec_ctx || avcodec_open2(codec_ctx, codec, NULL) < 0) {
            if (codec_ctx) avcodec_free_context(&codec_ctx);
            return NULL;
        }
    }

    d = malloc(sizeof(Decoder));
    d->codec_ctx = codec_ctx;
    d->frame = av_frame_alloc();
    d->sws_ctx = NULL;
    d->buffer = NULL;
    d->width = 1280;
    d->height = 720;
    d->sws_src_format = AV_PIX_FMT_YUV420P;
    d->hw_device_ctx = hw_device_ctx;

    return d;
}

static void free_decoder(Decoder *d) {
    if (d) {
        avcodec_close(d->codec_ctx);
        avcodec_free_context(&d->codec_ctx);
        av_frame_free(&d->frame);
        sws_freeContext(d->sws_ctx);
        av_free(d->buffer);
        free(d);
    }
}

static int decode_frame(Decoder *d, uint8_t *data, int size, uint8_t **out, int *w, int *h) {
	if (&data[0] == NULL)
		return;
    AVPacket pkt;
    av_init_packet(&pkt);
    pkt.data = data;
    pkt.size = size;

    int ret = avcodec_send_packet(d->codec_ctx, &pkt);
    av_packet_unref(&pkt);
	if (ret < 0) {
		printf("decode error3");
		return ret;
	}

      // æ¥æ”¶å¸§å¹¶å¤„ç†ç¡¬ä»¶åŠ é€Ÿ
    while (1) {
        ret = avcodec_receive_frame(d->codec_ctx, d->frame);
        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
			//printf("avcodec_receive_frame error %s\n", av_err2str(ret));
			//ret = 0;
			return ret;
		}
        if (ret < 0) {
			printf("decode error2");
			return ret;
		}

        // ç¡¬ä»¶å¸§è½¬æ¢åˆ°ç³»ç»Ÿå†…å­˜
        AVFrame *sw_frame = d->frame;
        if (d->frame->hw_frames_ctx) {
            sw_frame = av_frame_alloc();
            if (av_hwframe_transfer_data(sw_frame, d->frame, 0) < 0) {
                av_frame_free(&sw_frame);
                continue;
            }
        }

        // æ›´æ–°è½¬æ¢ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if (!d->sws_ctx || d->width != sw_frame->width || 
            d->height != sw_frame->height || d->sws_src_format != sw_frame->format) {
            
            sws_freeContext(d->sws_ctx);
            d->sws_ctx = sws_getContext(
                sw_frame->width, sw_frame->height,
                sw_frame->format,
                sw_frame->width, sw_frame->height,
                AV_PIX_FMT_RGBA,
                SWS_BILINEAR, NULL, NULL, NULL
            );
            
            d->width = sw_frame->width;
            d->height = sw_frame->height;
            d->sws_src_format = sw_frame->format;
            
            av_free(d->buffer);
            d->buffer = av_mallocz(sw_frame->width * sw_frame->height * 4);
        }

        // æ‰§è¡Œé¢œè‰²ç©ºé—´è½¬æ¢
        uint8_t *dst[] = { d->buffer };
        int dst_linesize[] = { d->width * 4 };
        sws_scale(d->sws_ctx, sw_frame->data, sw_frame->linesize,
                  0, d->height, dst, dst_linesize);

        if (sw_frame != d->frame) {
            av_frame_unref(d->frame);
            av_frame_free(&sw_frame);
        }

        *out = d->buffer;
        *w = d->width;
        *h = d->height;
        return 0;
    }
    return ret;
}

// æ–°å¢éŸ³é¢‘è§£ç å™¨ç»“æ„ä½“
typedef struct {
    AVCodecContext *codec_ctx;
    struct SwrContext *swr_ctx;
    AVFrame *frame;
    int target_sample_rate;
    int target_channels;
    enum AVSampleFormat target_sample_fmt;
    
    // æ–°å¢é‡ç”¨ç¼“å†²åŒº
    uint8_t **resampled_data;
    int resampled_linesize;
    int max_samples;
} AudioDecoder;

// åˆ›å»ºéŸ³é¢‘è§£ç å™¨
static AudioDecoder* create_audio_decoder(int sample_rate, int channels) {
    const AVCodec *codec = avcodec_find_decoder(AV_CODEC_ID_AAC);
    if (!codec) return NULL;

    AVCodecContext *codec_ctx = avcodec_alloc_context3(codec);
    if (!codec_ctx) return NULL;

    codec_ctx->sample_rate = sample_rate;
    codec_ctx->sample_fmt = AV_SAMPLE_FMT_FLTP;
    codec_ctx->sample_rate = 44100;
     // è®¾ç½®è§£ç å™¨å‚æ•°æ—¶å¢åŠ å®¹é”™
    codec_ctx->sample_rate = sample_rate;
    codec_ctx->bit_rate = 0; // è‡ªåŠ¨æ£€æµ‹
    codec_ctx->strict_std_compliance = FF_COMPLIANCE_STRICT;
    codec_ctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;


#if LIBAVCODEC_VERSION_MAJOR < 59
    codec_ctx->channels = channels;
    codec_ctx->channel_layout = av_get_default_channel_layout(channels);
#else
    //AVChannelLayout layout = AV_CHANNEL_LAYOUT_STEREO;
    AVChannelLayout layout;
    av_channel_layout_default(&layout, channels); // è‡ªåŠ¨æ¨å¯¼æ ‡å‡†å¸ƒå±€
    av_channel_layout_copy(&codec_ctx->ch_layout, &layout);
#endif
    
    codec_ctx->codec_type = AVMEDIA_TYPE_AUDIO;

	
    //codec_ctx->flags &= ~AV_CODEC_FLAG_AC_PRED;
    
    // è®¾ç½®æ­£ç¡®çš„profile
    //codec_ctx->profile = FF_PROFILE_AAC_LOW;

    if (avcodec_open2(codec_ctx, codec, NULL) < 0) {
        avcodec_free_context(&codec_ctx);
        return NULL;
    }

    AudioDecoder *d = malloc(sizeof(AudioDecoder));
    if (!d) {
        avcodec_close(codec_ctx);
        avcodec_free_context(&codec_ctx);
        return NULL;
    }
    memset(d, 0, sizeof(AudioDecoder));

    d->codec_ctx = codec_ctx;
    d->frame = av_frame_alloc();
    d->target_sample_rate = sample_rate;
    d->target_channels = channels;
    d->target_sample_fmt = AV_SAMPLE_FMT_S16;

    return d;
}

// åœ¨decode_audio_frameå¼€å¤´æ·»åŠ 
static int total_decode_time = 0;
static int frame_count = 0;
// è§£ç éŸ³é¢‘å¸§å¹¶è½¬æ¢æ ¼å¼
static int decode_audio_frame(AudioDecoder *d, uint8_t *data, int size, uint8_t **out, int *out_size) {
	struct timeval start, end;
    gettimeofday(&start, NULL);
    AVPacket pkt;
    av_init_packet(&pkt);
    pkt.data = data;
    pkt.size = size;

    int ret = avcodec_send_packet(d->codec_ctx, &pkt);
    av_packet_unref(&pkt);
     if (ret < 0) {
        char errbuf[256];
        av_strerror(ret, errbuf, sizeof(errbuf));
        fprintf(stderr, "Error sending packet: %s\n", errbuf);
        return ret;
    }

    ret = avcodec_receive_frame(d->codec_ctx, d->frame);
    if (ret < 0) return ret;

    // åˆ©ç”¨é¦–æ¬¡æ•°æ®åˆå§‹åŒ–é‡é‡‡æ ·å™¨
    if (!d->swr_ctx) {
        AVChannelLayout out_layout = AV_CHANNEL_LAYOUT_STEREO;
        swr_alloc_set_opts2(&d->swr_ctx,
                           &out_layout,                    // è¾“å‡ºå£°é“å¸ƒå±€
                           AV_SAMPLE_FMT_S16,              // è¾“å‡ºæ ¼å¼
                           44100,                         // è¾“å‡ºé‡‡æ ·ç‡
                           &d->frame->ch_layout,           // è¾“å…¥å£°é“å¸ƒå±€
                           d->frame->format,               // è¾“å…¥æ ¼å¼
                           d->frame->sample_rate,          // è¾“å…¥é‡‡æ ·ç‡
                           0, NULL);
        swr_init(d->swr_ctx);
    }
    if (!d->swr_ctx || swr_init(d->swr_ctx) < 0) {
        if (d) {
			avcodec_close(d->codec_ctx);
			avcodec_free_context(&d->codec_ctx);
			av_frame_free(&d->frame);
			swr_free(&d->swr_ctx);
			free(d);
		}
        return NULL;
    }
    
    // é‡é‡‡æ ·
    // é‡ç”¨ç¼“å†²åŒº
    int need_realloc = 0;
    int max_samples = av_rescale_rnd(d->frame->nb_samples, 
                                    d->target_sample_rate, 
                                    d->codec_ctx->sample_rate, 
                                    AV_ROUND_UP);
                                    
    if (max_samples > d->max_samples) {
        need_realloc = 1;
        d->max_samples = max_samples * 2; // é¢„åˆ†é…åŒå€ç©ºé—´
    }

    if (need_realloc || !d->resampled_data) {
        if (d->resampled_data) {
            av_freep(&d->resampled_data[0]);
            av_freep(&d->resampled_data);
        }
        
        av_samples_alloc_array_and_samples(&d->resampled_data, &d->resampled_linesize,
                                          d->target_channels, d->max_samples,
                                          d->target_sample_fmt, 0);
    }

    // ä½¿ç”¨é¢„åˆ†é…ç¼“å†²åŒº
    int converted_samples = swr_convert(d->swr_ctx, 
                                       d->resampled_data, d->max_samples,
                                       (const uint8_t **)d->frame->data, 
                                       d->frame->nb_samples);
    if (converted_samples < 0) {
        char errbuf[256];
        av_strerror(converted_samples, errbuf, sizeof(errbuf));
        fprintf(stderr, "SWR convert error: %s\n", errbuf);
        // ...é‡Šæ”¾èµ„æº...
        av_freep(&d->resampled_data[0]);
        av_freep(&d->resampled_data);
        return -1;
    }

    int data_size = converted_samples * d->target_channels * av_get_bytes_per_sample(d->target_sample_fmt);
    //uint8_t *pcm_copy = malloc(data_size);
    //if (!pcm_copy) {
    //    av_freep(&d->resampled_data[0]);
    //    av_freep(&d->resampled_data);
    //    return -1;
    //}
    //memcpy(pcm_copy, d->resampled_data[0], data_size);

    //av_freep(&d->resampled_data[0]);
    //av_freep(&d->resampled_data);

    //*out = pcm_copy;
    *out = d->resampled_data[0];
    *out_size = data_size;
    
    gettimeofday(&end, NULL);
    long decode_usec = (end.tv_sec - start.tv_sec)*1000000 + 
                      (end.tv_usec - start.tv_usec);
    total_decode_time += decode_usec;
    frame_count++;
    
    // æ¯50å¸§æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    if (frame_count % 50 == 0) {
        fprintf(stderr, "[Audio] Avg decode time: %.2fms | Queue: %d/%d\n",
               (total_decode_time/1000.0)/frame_count,
               (audio_queue_head - audio_queue_tail + AUDIO_QUEUE_SIZE) % AUDIO_QUEUE_SIZE,
               AUDIO_QUEUE_SIZE);
        total_decode_time = 0;
        frame_count = 0;
    }
    
    return 0;
}

// åœ¨å…¨å±€å˜é‡åŒºæ·»åŠ 
#define AUDIO_BUFFER_SIZE (44100 * 2 * 2 / 5)
static uint8_t audio_buffer[AUDIO_BUFFER_SIZE];
static int audio_buffer_pos = 0;

// å…¨å±€éŸ³é¢‘è§£ç å™¨å®ä¾‹
static AudioDecoder *audio_decoder = NULL;

// å£°æ˜Goå›è°ƒ
extern void audioPCMCallback(void* data, int len);

static void process_single_frame(uint8_t* data, int len) {
    // æ­¤å¤„å¤„ç†å•ä¸ªå®Œæ•´ADTSå¸§
    uint8_t *pcm_data = NULL;
    int pcm_size = 0;
    
    uint8_t adts_header[7];
    int profile = 1;
    int sample_rate_idx = 4;
    int channels = 2;
    int frame_length = len + 7;

    adts_header[0] = 0xFF;
    adts_header[1] = 0xF1;
    adts_header[2] = (profile << 6) | (sample_rate_idx << 2) | (channels >> 2);
    adts_header[3] = (channels << 6) | (frame_length >> 11);
    adts_header[4] = (frame_length >> 3) & 0xFF;
    adts_header[5] = ((frame_length & 0x07) << 5) | 0x1F;
    adts_header[6] = 0xFC;

    uint8_t *aac_data = malloc(len + 7);
    memcpy(aac_data, adts_header, 7);
    memcpy(aac_data + 7, data, len);

	if (!audio_decoder) {
        int sample_rate = 44100; // æ ¹æ®sample_rate_idxè½¬æ¢
        audio_decoder = create_audio_decoder(sample_rate, 2);
        if (!audio_decoder) {
            fprintf(stderr, "æ— æ³•åˆ›å»ºéŸ³é¢‘è§£ç å™¨\n");
            return;
        }
    }

    int ret = decode_audio_frame(audio_decoder, aac_data, len+7, &pcm_data, &pcm_size);
    
    if (ret == 0 && pcm_data != NULL) {
        audioPCMCallback(pcm_data, pcm_size);
        //free(pcm_data);
    }
}

// æ”¾å…¥é˜Ÿåˆ—å‡½æ•°
static void enqueue_audio_packet(uint8_t *data, int len) {
    pthread_mutex_lock(&audio_queue_mutex);

    // åŠ¨æ€é˜Ÿåˆ—è°ƒæ•´ç­–ç•¥
    int queue_usage = (audio_queue_head - audio_queue_tail + AUDIO_QUEUE_SIZE) % AUDIO_QUEUE_SIZE;
    if (queue_usage > AUDIO_QUEUE_SIZE * 0.8) {
        // å½“é˜Ÿåˆ—ä½¿ç”¨è¶…è¿‡80%æ—¶ï¼Œæ¿€è¿›ä¸¢å¼ƒæ—§å¸§
        int drop_count = queue_usage / 2;
        while (drop_count-- > 0) {
            free(audio_packet_queue[audio_queue_tail].data);
            audio_queue_tail = (audio_queue_tail + 1) % AUDIO_QUEUE_SIZE;
        }
    }
    
    // ä¸¢å¼ƒæ—§å¸§ç­–ç•¥ï¼šå½“é˜Ÿåˆ—å‰©ä½™ç©ºé—´å°äº10%æ—¶æ¸…ç©ºé˜Ÿåˆ—
    if ((audio_queue_head + 1) % AUDIO_QUEUE_SIZE == audio_queue_tail) {
        // æ¸…ç©ºé˜Ÿåˆ—
        while (audio_queue_tail != audio_queue_head) {
            free(audio_packet_queue[audio_queue_tail].data);
            audio_queue_tail = (audio_queue_tail + 1) % AUDIO_QUEUE_SIZE;
        }
    }

    // åˆ†é…å†…å­˜å¹¶æ‹·è´æ•°æ®
    AudioPacket pkt;
    pkt.data = malloc(len);
    pkt.size = len;
    memcpy(pkt.data, data, len);
    
    audio_packet_queue[audio_queue_head] = pkt;
    audio_queue_head = (audio_queue_head + 1) % AUDIO_QUEUE_SIZE;
    
    pthread_cond_signal(&audio_queue_cond);
    pthread_mutex_unlock(&audio_queue_mutex);
}

// å¤„ç†çº¿ç¨‹å‡½æ•°
static void* process_audio_frames(void* arg) {
    while (audio_processing) {
        pthread_mutex_lock(&audio_queue_mutex);
        
        while (audio_queue_tail == audio_queue_head && audio_processing) {
            pthread_cond_wait(&audio_queue_cond, &audio_queue_mutex);
        }
        
        if (!audio_processing) break;
        
        AudioPacket pkt = audio_packet_queue[audio_queue_tail];
        audio_queue_tail = (audio_queue_tail + 1) % AUDIO_QUEUE_SIZE;
        
        pthread_mutex_unlock(&audio_queue_mutex);
        
        // è°ƒç”¨åŸæœ‰å¤„ç†é€»è¾‘
        process_single_frame(pkt.data, pkt.size);
        free(pkt.data);
    }
    return NULL;
}

// åˆå§‹åŒ–éŸ³é¢‘å¤„ç†çº¿ç¨‹
static void init_audio_processing() {
    audio_processing = 1;
    pthread_t thread;
    pthread_create(&thread, NULL, process_audio_frames, NULL);
}

// åœæ­¢éŸ³é¢‘å¤„ç†
static void stop_audio_processing() {
    pthread_mutex_lock(&audio_queue_mutex);
    audio_processing = 0;
    pthread_cond_signal(&audio_queue_cond);
    pthread_mutex_unlock(&audio_queue_mutex);
}

// ä¿®æ”¹åçš„éŸ³é¢‘å›è°ƒ
static void audioStreamCallback(void* data, int len) {
	addaudio();
	if (len == 2) {
		//è¯¥2ä¸ªå­—èŠ‚ä¸ºmytæ·»åŠ çš„æ ‡è®° ä¸ç”¨å¤„ç† 
		return;
	}
    
    //process_single_frame(data, len);
    enqueue_audio_packet(data, len);
}


// ä¸ºç®€åŒ–è°ƒç”¨ï¼ŒåŒ…è£… startVideoStream æˆä¸º start_stream å‡½æ•°
static inline int start_stream(long handle, int w, int h, int bitrate) {
    return startVideoStream(handle, w, h, bitrate, videoStreamCallback, audioStreamCallback);
}

*/
import "C"

import (
	"errors"
	"fmt"
	"image"
	"image/color"
	"image/draw"
	//"io/ioutil"
	"sync"
	"time"
	"unsafe"
	"math"
	//"reflect"
	"flag"
	"os"
	"bytes"
	"mime/multipart"
	"io"
	"net/http"
	"strings"
	"path/filepath"
	"runtime"
	"encoding/json"
	"unicode"

	"fyne.io/fyne/v2"
	"fyne.io/fyne/v2/app"
	"fyne.io/fyne/v2/canvas"
	"fyne.io/fyne/v2/container"
	"fyne.io/fyne/v2/widget"
	"fyne.io/fyne/v2/dialog"
    "fyne.io/fyne/v2/theme"
	"github.com/disintegration/imaging"
	"github.com/hajimehoshi/oto"
)

var audiodelta = 0
var lastAudiodelta = 0
var videodelta = 0
var lastVideodelta = 0

//export addaudio
func addaudio() {
	if audiodelta < 1000000 {
		audiodelta++
	} else {
		audiodelta = 1
	}
}

// -------------------- SDK å°è£…æ¨¡å— --------------------

// openDevice å°è£… openDevice æ¥å£
func openDevice(ip string, port int, timeout int) (C.long, error) {
	cip := C.CString(ip)
	defer C.free(unsafe.Pointer(cip))
	handle := C.openDevice(cip, C.int(port), C.long(timeout))
	if handle <= 0 {
		return 0, errors.New("openDevice è°ƒç”¨å¤±è´¥")
	}
	return handle, nil
}

// closeDevice å°è£… closeDevice æ¥å£
func closeDevice(handle C.long) error {
	ret := C.closeDevice(handle)
	if ret <= 0 {
		return errors.New("closeDevice è°ƒç”¨å¤±è´¥")
	}
	handle = 0;
	return nil
}

// startVideoStream å°è£… startVideoStream æ¥å£ï¼ˆé€šè¿‡æˆ‘ä»¬åœ¨ C ä¸­åŒ…è£…çš„ start_streamï¼‰
func startVideoStream(handle C.long, width, height, bitrate int) error {
	fmt.Println("start_stream start", handle)
	ret := C.start_stream(handle, C.int(width), C.int(height), C.int(bitrate))
	if ret != 1 {
		return errors.New("startVideoStream è°ƒç”¨å¤±è´¥")
	}
	fmt.Println("start_stream ret", ret)
	return nil
}

// stopVideoStream å°è£… stopVideoStream æ¥å£
func stopVideoStream(handle C.long) error {
	ret := C.stopVideoStream(handle)
	if ret != 1 {
		return errors.New("stopVideoStream è°ƒç”¨å¤±è´¥")
	}
	return nil
}

// takeScreenshot å°è£… takeCaptrueCompress æ¥å£ï¼Œè¿”å›å‹ç¼©åçš„æˆªå›¾æ•°æ®ï¼ˆä¾‹å¦‚ PNGï¼‰
func takeScreenshot(handle C.long, compType int, quality int) ([]byte, error) {
	var length C.int
	ret := C.takeCaptrueCompress(handle, C.int(compType), C.int(quality), &length)
	if ret == nil {
		return nil, errors.New("takeCaptrueCompress è°ƒç”¨å¤±è´¥")
	}
	defer C.freeRpcPtr(unsafe.Pointer(ret))
	data := C.GoBytes(unsafe.Pointer(ret), length)
	return data, nil
}

// -------------------- æ¨æµåŠ h264 è§£ç ï¼ˆä¼ªå®ç°ï¼‰ --------------------

// generateDummyImage ç”Ÿæˆä¸€å¼ çº¯è‰²å›¾åƒï¼Œä¾›å±•ç¤ºä½¿ç”¨
func generateDummyImage(w, h int) image.Image {
	img := image.NewRGBA(image.Rect(0, 0, w, h))
	// ç”Ÿæˆéšæœºé¢œè‰²ï¼Œè¿™é‡Œå›ºå®šä¸ºè“è‰²
	blue := color.RGBA{0, 0, 255, 255}
	draw.Draw(img, img.Bounds(), &image.Uniform{blue}, image.Point{}, draw.Src)
	return img
}

type VideoFrame struct {
    Rotation int    // 0-3 å¯¹åº” 0Â°, 90Â°, 180Â°, 270Â°
    Data     []byte
}

type AudioFrame struct {
    Data     []byte
}

// -------------------- æ¨æµåŠ h264 è§£ç æ”¹è¿› --------------------
const (
	MaxFrameBuffer = 30 // ç¼“å†²30å¸§é˜²æ­¢å¡é¡¿
)

var (
	videoStreamChan  = make(chan VideoFrame, MaxFrameBuffer)
	projectionWindow fyne.Window
	projectionImg    *canvas.Image
	interactiveImg   *InteractiveImage
	currentRotation = -1
)

//export videoStreamCallback
func videoStreamCallback(rot C.int, data unsafe.Pointer, length C.int) {
	// éé˜»å¡æ–¹å¼å‘é€ï¼Œä¿ç•™æœ€æ–°30å¸§
	select {
	case videoStreamChan <- VideoFrame{
		Rotation: int(rot),
		Data:     C.GoBytes(data, length),
	}:
		if videodelta < 1000000 {
			videodelta++
		} else {
			videodelta = 1
		}
		//fmt.Println("æ—‹è½¬æ”¹å˜1", currentRotation, int(rot))
		if currentRotation != int(rot) {
			currentRotation = int(rot)
			var currentWidth float32
			var currentHeight float32
			// æ—‹è½¬æ”¹å˜ï¼Œåˆ·æ–°çª—å£å¤§å°
			switch currentRotation {
				case 0, 2: // ç«–å±æ¨¡å¼
					currentWidth = 540
					currentHeight = 960
				default: // æ¨ªå±æ¨¡å¼
					currentWidth = 960
					currentHeight = 540
			}
			//fmt.Println("æ—‹è½¬æ”¹å˜", currentRotation, currentWidth, currentHeight)
			projectionWindow.Resize(fyne.NewSize(currentWidth, currentHeight))
			//session.lock.Lock()
		
			// è·å–åŸå§‹å¤§å°ç”¨æ¥è®¡ç®—å›¾åƒéšçª—å£ç­‰æ¯”ç¼©æ”¾å¹¶ç»´æŒåœ¨çª—å£ä¸­é—´
			orgWidth := float64(projectionImg.Image.Bounds().Dx())
			orgHeight := float64(projectionImg.Image.Bounds().Dy())
			
			// è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
			scale := math.Min(
				float64(currentWidth-8)/orgWidth,
				float64(currentHeight-8)/orgHeight,
			)

			// è®¡ç®—å®é™…æ˜¾ç¤ºå°ºå¯¸å’Œä½ç½®
			newWidth := float32(orgWidth * scale)
			newHeight := float32(orgHeight * scale)
			
			//fmt.Println("1å¤§å°æ”¹å˜", newWidth, newHeight)
			interactiveImg.Resize(fyne.NewSize(newWidth, newHeight))
			//main_content.Move(fyne.NewPos(size.Width/2-(newWidth/2), 0))
			interactiveImg.Refresh()
			//session.lock.Unlock()
			//projectionWindow
		}
	default:
		// ä¸¢å¼ƒæœ€æ—§å¸§
		<-videoStreamChan
		videoStreamChan <- VideoFrame{
			Rotation: int(rot),
			Data:     C.GoBytes(data, length),
		}
	}
}

// å›¾åƒæ—‹è½¬å‡½æ•°
func rotateImage(src image.Image, rotation int) image.Image {
	//fmt.Println("è§’åº¦2", rotation)
    switch rotation {
    case 2: // 90Â°
        return imaging.Rotate90(src)
    case 3: // 180Â°
        return imaging.Rotate180(src)
    case 0: // 270Â°
        return imaging.Rotate270(src)
    default: // 0Â°
        return src
    }
}

func UNUSED(x ...interface{}) {}

type H264Decoder struct {
	decoder   *C.Decoder
	lastWidth  int
	lastHeight int
	imgBuffer  *image.RGBA
}

func NewH264Decoder() (*H264Decoder, error) {
	d := C.create_decoder()
	if d == nil {
		return nil, fmt.Errorf("æ— æ³•åˆ›å»ºè§£ç å™¨")
	}
	return &H264Decoder{decoder: d}, nil
}

func (d *H264Decoder) Close() {
	C.free_decoder(d.decoder)
}

func (d *H264Decoder) Decode(data []byte) (image.Image, error) {
	var out *C.uint8_t
	var w, h C.int

	ret := C.decode_frame(d.decoder, (*C.uint8_t)(&data[0]), C.int(len(data)), &out, &w, &h)
	// å¤„ç†æ­£å¸¸ç­‰å¾…æƒ…å†µ
	if ret == 1 {
		return nil, nil // æ­£å¸¸ç­‰å¾…æ›´å¤šæ•°æ®
	}
	if ret != 0 {
		return nil, fmt.Errorf("è§£ç å¤±è´¥: %d", ret)
	}

	currentWidth := int(w)
	currentHeight := int(h)

	// æ£€æŸ¥å°ºå¯¸å˜åŒ–
	if d.lastWidth != currentWidth || d.lastHeight != currentHeight {
		d.imgBuffer = image.NewRGBA(image.Rect(0, 0, currentWidth, currentHeight))
		d.lastWidth = currentWidth
		d.lastHeight = currentHeight
	}

	// å®Œæ•´å¤åˆ¶å›¾åƒæ•°æ®
	rgb := C.GoBytes(unsafe.Pointer(out), C.int(currentWidth*currentHeight*4))
	copy(d.imgBuffer.Pix, rgb)

	return d.imgBuffer, nil
}

func addADTSHeader(frame []byte, sampleRate, channels int) []byte {
    profile := 1 // AAC LC
    sampleRateIndex := 4 // 44100 Hz
    channelConfig := channels
    frameLength := len(frame) + 7

    adtsHeader := make([]byte, 7)
    // Syncword 12 bits: 0xFFF
    adtsHeader[0] = 0xFF
    adtsHeader[1] = 0xF0 
    // Profile 2 bits, sample rate index 4 bits
    adtsHeader[2] = byte((profile-1)<<6) | byte(sampleRateIndex<<2)
    // Channel config 3 bits, frame length 13 bits
    adtsHeader[3] = byte(channelConfig<<6) | byte((frameLength>>11)&0x03)
    adtsHeader[4] = byte((frameLength >> 3) & 0xFF)
    adtsHeader[5] = byte((frameLength&0x07)<<5) | 0x1F
    adtsHeader[6] = 0xFC

    return append(adtsHeader, frame...)
}

var (
    audioPlayer *oto.Player
    audioContext *oto.Context
)

// ä½¿ç”¨å†…å­˜æ± é¿å…GCåœé¡¿
var pcmPool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 0, 4096) 
    },
}

//export audioPCMCallback
func audioPCMCallback(data unsafe.Pointer, length C.int) {
    buf := pcmPool.Get().([]byte)
    defer pcmPool.Put(buf[:0])
    
    // é‡ç”¨ç¼“å†²åŒºï¼ˆé›¶æ‹·è´ï¼‰
    buf = (*[1 << 28]byte)(data)[:length:length]
    
    if audioPlayer != nil {
        audioPlayer.Write(buf)
    }
}

func initAudio() error {
    // å‚æ•°ä¸Cä»£ç ä¸­çš„ç›®æ ‡æ ¼å¼ä¸€è‡´ï¼š44100Hz, 2å£°é“, 16ä½
    var err error
    // å°†ç¼“å†²åŒºä»4KBå¢åŠ åˆ°40KBï¼ˆçº¦200msç¼“å†²ï¼‰
    const bufferSize = 44100 * 2 * 2 / 5 // 44100Hz * 16bit * 2ch /5 = 35280 bytes
    audioContext, err := oto.NewContext(44100, 2, 2, bufferSize)
    if err != nil {
        return err
    }
    audioPlayer = audioContext.NewPlayer()
    C.init_audio_processing()
    return nil
}

// ä¿®æ”¹åçš„è§£ç æ˜¾ç¤ºå‡½æ•°
func decodeAndDisplayVideo(img *canvas.Image, stopChan <-chan struct{}, wg *sync.WaitGroup) {
    defer wg.Done()

    decoder, err := NewH264Decoder()
    if err != nil {
        fmt.Println("åˆ›å»ºè§£ç å™¨å¤±è´¥:", err)
        return
    }
    defer decoder.Close()

	for {
		select {
			case frame := <-videoStreamChan:
				decodedImg, err := decoder.Decode(frame.Data)
				if err != nil {
					fmt.Println("è§£ç é”™è¯¯:", err)
					continue
				}
				if decodedImg == nil {
					continue // æ­£å¸¸ç­‰å¾…æ•°æ®
				}
				//fmt.Println("å½“å‰æ—‹è½¬:", frame.Rotation)

				// åº”ç”¨æ—‹è½¬å¹¶æ˜¾ç¤º
				rotatedImg := rotateImage(decodedImg, frame.Rotation)
				img.Image = rotatedImg
				img.Refresh()
			//case data := <-audioStreamChan:
			//	fmt.Println("éŸ³é¢‘", data)
			//	adtsData := addADTSHeader(data, 44100, 2)
			//	ioutil.WriteFile("audio.aac", adtsData, 0644)
			default:

		case <-stopChan:
			return
		}
	}
}

// -------------------- GUI æ”¹è¿› --------------------
var (
	currentTicker    *time.Ticker
	currentStopChan  chan struct{}
	intervalSelect   *widget.Select
)

// -------------------- GUI ä¸ä¸šåŠ¡é€»è¾‘ --------------------

var (
	discoveredDevices []string
	selectedDevice    string
	sdkHandle         C.long
	stopStreamChan    chan struct{}
	wg                sync.WaitGroup
)

func (s *TouchSession) mapCoordinates(pos fyne.Position) (x, y int) {
    s.lock.RLock()
    defer s.lock.RUnlock()

    if s.windowSize.Width == 0 || s.windowSize.Height == 0 {
        return 0, 0
    }
    
    s.rotation = currentRotation

    // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆè€ƒè™‘è®¾å¤‡æ—‹è½¬ï¼‰
    var scaleX, scaleY float64
    switch s.rotation {
    case 0, 2: // ç«–å±æ¨¡å¼
        scaleX = float64(s.sourceSize.Height) / float64(s.windowSize.Width)
        scaleY = float64(s.sourceSize.Width) / float64(s.windowSize.Height)
    default: // æ¨ªå±æ¨¡å¼
        scaleX = float64(s.sourceSize.Width) / float64(s.windowSize.Width)
        scaleY = float64(s.sourceSize.Height) / float64(s.windowSize.Height)
    }

    // åæ ‡æ˜ å°„
    switch s.rotation {
    case 0: // è®¾å¤‡270Â°æ—‹è½¬
        return int(float64(pos.X) * scaleX), int(float64(pos.Y)*scaleY)            
    case 3: // 180Â°
        return int(float64(s.sourceSize.Width) - float64(pos.X)*scaleX),
            int(float64(s.sourceSize.Height) - float64(pos.Y)*scaleY)
    case 2: // 90Â°
        return int(float64(pos.Y) * scaleY),
            int(float64(s.sourceSize.Width) - float64(pos.X)*scaleX)
    default: // 0Â°
        return int(float64(pos.X) * scaleX),
            int(float64(pos.Y) * scaleY)
    }
}

// æ£€æŸ¥å¹¶ç»´æŒè¿æ¥
func (s *TouchSession) checkHandle(ipaddr string, port int, bakport int) error {
    if s.handle <= 0 {
        handle, err := openDevice(ipaddr, port, 3)
        if err != nil {
			handle, err := openDevice(ipaddr, bakport, 3)
			if err != nil {
				return err
			} else {
				s.handle = C.long(handle)
			}
        } else {
			s.handle = C.long(handle)
        }
    }
    return nil
}

type InteractiveImage struct {
    *canvas.Image
    onTapped           func(pos fyne.Position)
    onTappedSecondary  func(pos fyne.Position)
    onScrolled         func(ev *fyne.ScrollEvent)
    onDragged		   func(d *fyne.DragEvent)
    onDragEnd		   func()
}

func NewInteractiveImage(img *canvas.Image) *InteractiveImage {
    return &InteractiveImage{Image: img}
}

// å®ç°Tappableæ¥å£
func (i *InteractiveImage) Tapped(ev *fyne.PointEvent) {
    if i.onTapped != nil {
        i.onTapped(ev.Position)
    }
}

// å®ç°TappedSecondaryæ¥å£
func (i *InteractiveImage) TappedSecondary(ev *fyne.PointEvent) {
    if i.onTappedSecondary != nil {
        i.onTappedSecondary(ev.Position)
    }
}

// å®ç°Scrollableæ¥å£
func (i *InteractiveImage) Scrolled(ev *fyne.ScrollEvent) {
    if i.onScrolled != nil {
        i.onScrolled(ev)
    }
}

// å®ç°Draggedæ¥å£
func (i *InteractiveImage) Dragged(ev *fyne.DragEvent) {
    if i.onDragged != nil {
        i.onDragged(ev)
    }
}

// å®ç°DragEndæ¥å£
func (i *InteractiveImage) DragEnd() {
    if i.onDragEnd != nil {
        i.onDragEnd()
    }
}

func (b *InteractiveImage) CreateRenderer() fyne.WidgetRenderer {
	return widget.NewSimpleRenderer(b.Image)
}

type TouchSession struct {
    handle       C.long
    rotation     int
    windowSize   fyne.Size
    sourceSize   fyne.Size
    touchPoints  map[int]fyne.Position
    lock         sync.RWMutex
}

func NewTouchSession(sourceW, sourceH int) *TouchSession {
    return &TouchSession{
        sourceSize:  fyne.NewSize(float32(sourceW), float32(sourceH)),
        touchPoints: make(map[int]fyne.Position),
    }
}

type SizeWatcher struct {
    widget.BaseWidget
    OnSizeChanged func(fyne.Size)
}

func NewSizeWatcher(callback func(fyne.Size)) *SizeWatcher {
    w := &SizeWatcher{OnSizeChanged: callback}
    w.ExtendBaseWidget(w)
    return w
}

func (w *SizeWatcher) CreateRenderer() fyne.WidgetRenderer {
    return &sizeWatcherRenderer{
        widget: w,
        rect:   canvas.NewRectangle(color.Transparent),
    }
}

type sizeWatcherRenderer struct {
    widget *SizeWatcher
    rect   *canvas.Rectangle
}

func (r *sizeWatcherRenderer) Layout(size fyne.Size) {
    r.rect.Resize(size)
    if r.widget.OnSizeChanged != nil {
        r.widget.OnSizeChanged(size)
    }
}

func (r *sizeWatcherRenderer) MinSize() fyne.Size     { return fyne.NewSize(0, 0) }
func (r *sizeWatcherRenderer) Refresh()               {}
func (r *sizeWatcherRenderer) Objects() []fyne.CanvasObject { return []fyne.CanvasObject{r.rect} }
func (r *sizeWatcherRenderer) Destroy()               {}

func setupInputHandlers(img *InteractiveImage, session *TouchSession) {
    // ç‚¹å‡»äº‹ä»¶
    img.onTapped = func(pos fyne.Position) {
		//fmt.Println("ç‚¹å‡»")
        x, y := session.mapCoordinates(pos)
        
		if audiodelta != 0 && lastAudiodelta == audiodelta && lastVideodelta == videodelta {
			fmt.Println("é‡è¿", audiodelta, lastAudiodelta)
			C.stopVideoStream(C.long(session.handle))
			startVideoStream(C.long(session.handle), 1280, 720, 2000);
		}
		lastAudiodelta = audiodelta
		lastVideodelta = videodelta
        C.touchClick(session.handle, 0, C.int(x), C.int(y))
        //C.touchUp(session.handle, 0, C.int(x), C.int(y))
    }
    
    // å³é”®ç‚¹å‡»
    img.onTappedSecondary = func(pos fyne.Position) {
		//fmt.Println("å³é”®ç‚¹å‡»")
		if audiodelta != 0 && lastAudiodelta == audiodelta && lastVideodelta == videodelta {
			fmt.Println("é‡è¿", audiodelta, lastAudiodelta)
			C.stopVideoStream(C.long(session.handle))
			startVideoStream(C.long(session.handle), 1280, 720, 2000);
		}
		lastAudiodelta = audiodelta
		lastVideodelta = videodelta
        // å³é”®è¿”å›
        C.keyPress(session.handle, 4)
    }

    // æ»šåŠ¨äº‹ä»¶
    img.onScrolled = func(ev *fyne.ScrollEvent) {
		if audiodelta != 0 && lastAudiodelta == audiodelta && lastVideodelta == videodelta {
			fmt.Println("é‡è¿", audiodelta, lastAudiodelta)
			C.stopVideoStream(C.long(session.handle))
			startVideoStream(C.long(session.handle), 1280, 720, 2000);
		}
		lastAudiodelta = audiodelta
		lastVideodelta = videodelta
		//fmt.Println("æ»šåŠ¨", ev)
        startX, startY := session.mapCoordinates(ev.Position)
        delta := int(ev.Scrolled.DY * 20)
        C.swipe(session.handle, 0, 
            C.int(startX), C.int(startY),
            C.int(startX), C.int(startY-delta),
            C.long(100), C.bool(false))
    }
    
    // æ»‘åŠ¨äº‹ä»¶
    img.onDragged = func(d *fyne.DragEvent) {
		x, y := session.mapCoordinates(d.PointEvent.Position)
        if _, ok := session.touchPoints[0]; !ok {
            if audiodelta != 0 && lastAudiodelta == audiodelta && lastVideodelta == videodelta {
				C.stopVideoStream(C.long(session.handle))
				fmt.Println("é‡è¿", audiodelta, lastAudiodelta)
				startVideoStream(C.long(session.handle), 1280, 720, 2000);
			}
			lastAudiodelta = audiodelta
			lastVideodelta = videodelta
            C.touchDown(session.handle, 0, C.int(x), C.int(y))
        } else {
            C.touchMove(session.handle, 0, C.int(x), C.int(y))
        }
        session.touchPoints[0] = d.PointEvent.Position
    }
    
    // æ»‘åŠ¨ç»“æŸ
    img.onDragEnd = func() {
        if audiodelta != 0 && lastAudiodelta == audiodelta && lastVideodelta == videodelta {
			C.stopVideoStream(C.long(session.handle))
			fmt.Println("é‡è¿", audiodelta, lastAudiodelta)
			startVideoStream(C.long(session.handle), 1280, 720, 2000);
		}
		lastAudiodelta = audiodelta
		lastVideodelta = videodelta
		//fmt.Println("æ‹–åŠ¨ç»“æŸ")
		x, y := session.mapCoordinates(session.touchPoints[0])
		C.touchUp(session.handle, 0, C.int(x), C.int(y))
		session.touchPoints = make(map[int]fyne.Position)
    }
}

type ExecResult struct {
    ExitCode int
    Stdout   string
    Stderr   string
}

func sanitizeString(s string) string {
    return strings.ToValidUTF8(strings.Map(func(r rune) rune {
        if unicode.IsControl(r) && r != '\n' && r != '\t' {
            return -1
        }
        return r
    }, s), "ï¿½")
}

func dockerExec(ip string, port int, containerID string, cmd []string) (*ExecResult, error) {
    // 1. åˆ›å»ºexecå®ä¾‹
    createURL := fmt.Sprintf("http://%s:%d/containers/%s/exec", ip, port, containerID)
    reqBody := map[string]interface{}{
        "AttachStdout": true,
        "AttachStderr": true,
        "Cmd":          cmd,
    }
    
    resp, err := postJSON(createURL, reqBody)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    var execCreate struct{ Id string }
    if err := json.NewDecoder(resp.Body).Decode(&execCreate); err != nil {
        return nil, err
    }

    // 2. å¯åŠ¨execå¹¶æ•è·è¾“å‡º
    startURL := fmt.Sprintf("http://%s:%d/exec/%s/start", ip, port, execCreate.Id)
    resp, err = postJSON(startURL, map[string]interface{}{
        "Detach": false,
        "Tty":    false,
    })
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    // 3. è¯»å–æµå¼è¾“å‡ºï¼ˆDocker APIå¸§æ ¼å¼ï¼‰
    var (
        stdout, stderr bytes.Buffer
        rawResponse    bytes.Buffer
    )
    tee := io.TeeReader(resp.Body, &rawResponse)
    dec := json.NewDecoder(tee)
    for dec.More() {
        var frame struct {
            Type string `json:"Type"`
            Body string `json:"Body"`
        }
        if err := dec.Decode(&frame); err != nil {
            //fmt.Println("JSONè§£æå¤±è´¥ï¼ŒåŸå§‹æ•°æ®: %q", rawResponse.String())
            //return nil, fmt.Errorf("å“åº”è§£æå¤±è´¥: %v", err)
            break
        }

        cleaned := sanitizeString(frame.Body)
        switch frame.Type {
        case "stdout":
            stdout.WriteString(cleaned)
        case "stderr":
            stderr.WriteString(cleaned)
        }
    }

    // æ£€æŸ¥æœªè§£ææ•°æ®
    //if rest, _ := io.ReadAll(dec.Buffered()); len(rest) > 0 {
    //    fmt.Println("æœªè§£æçš„å“åº”æ•°æ®: %q", rest)
    //}

    // 4. è·å–é€€å‡ºç 
    inspectURL := fmt.Sprintf("http://%s:%d/exec/%s/json", ip, port, execCreate.Id)
    resp, err = http.Get(inspectURL)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    var execInspect struct {
        ExitCode int `json:"ExitCode"`
    }
    if err := json.NewDecoder(resp.Body).Decode(&execInspect); err != nil {
        return nil, err
    }

    return &ExecResult{
        ExitCode: execInspect.ExitCode,
        Stdout:   stdout.String(),
        Stderr:   stderr.String(),
    }, nil
}

// é€šç”¨JSON POSTè¯·æ±‚
func postJSON(url string, data interface{}) (*http.Response, error) {
    body := new(bytes.Buffer)
    if err := json.NewEncoder(body).Encode(data); err != nil {
        return nil, err
    }
    
    req, err := http.NewRequest("POST", url, body)
    if err != nil {
        return nil, err
    }
    req.Header.Set("Content-Type", "application/json")
    
    return http.DefaultClient.Do(req)
}

func uploadFile(ip string, port int, filePath string) error {
    // æ‰“å¼€æ–‡ä»¶
    file, err := os.Open(filePath)
    if err != nil {
        return err
    }
    defer file.Close()

    // åˆ›å»ºmultipartè¯·æ±‚
    body := &bytes.Buffer{}
    writer := multipart.NewWriter(body)
    part, err := writer.CreateFormFile("file", filepath.Base(filePath))
    if err != nil {
        return err
    }

    // æ‹·è´æ–‡ä»¶å†…å®¹
    if _, err = io.Copy(part, file); err != nil {
        return err
    }
    writer.Close()

    // åˆ›å»ºè¯·æ±‚
    url := fmt.Sprintf("http://%s:%d/upload", ip, port)
    req, err := http.NewRequest("POST", url, body)
    if err != nil {
        return err
    }

    // è®¾ç½®è¯·æ±‚å¤´
    req.Header.Set("Content-Type", writer.FormDataContentType())

    // å‘é€è¯·æ±‚
    client := &http.Client{Timeout: 30 * time.Second}
    resp, err := client.Do(req)
    if err != nil {
        return err
    }
    defer resp.Body.Close()

    // æ£€æŸ¥å“åº”
    if resp.StatusCode != http.StatusOK {
        body, _ := io.ReadAll(resp.Body)
        return fmt.Errorf("æœåŠ¡å™¨é”™è¯¯: %s", string(body))
    }
    return nil
}

func handleAPKInstall(ip string, uploadPort int, containerID string, 
    dockerPort int, localPath string) error {
    
    // 1. ä¸Šä¼ æ–‡ä»¶
    if err := uploadFile(ip, uploadPort, localPath); err != nil {
        return fmt.Errorf("ä¸Šä¼ å¤±è´¥: %v", err)
    }

    // 2. å‡†å¤‡å®¹å™¨å†…è·¯å¾„
    fileName := filepath.Base(localPath)
    uploadPath := "/sdcard/upload/" + fileName
    installPath := "/data/local/tmp/" + fileName
    
    // ä¿®æ”¹å‘½ä»¤æ„é€ æ–¹å¼ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®è½¬ä¹‰
	//installPath := fmt.Sprintf("/data/local/tmp/%s", shellEscape(filepath.Base(localPath)))


    // 3. æ‰§è¡Œå®¹å™¨å†…å‘½ä»¤
	commands := []struct{
		Cmd     string
		Message string
	}{
		{fmt.Sprintf("mv '%s' '%s'", uploadPath, installPath), "ç§»åŠ¨æ–‡ä»¶ä¸­..."},
		{fmt.Sprintf("pm install -r '%s'", installPath), "å®‰è£…APKä¸­..."},
		{fmt.Sprintf("rm -f '%s'", installPath), "æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."},
	}

    //var fullOutput strings.Builder
    for _, step := range commands {
        //updateProgress(step.Message)
        
        result, err := dockerExec(ip, dockerPort, containerID, []string{"sh", "-c", step.Cmd})
        if err != nil {
            return fmt.Errorf("æ‰§è¡Œå¤±è´¥: %v", err)
        }

        // è®°å½•å®Œæ•´è¾“å‡º
        //fullOutput.WriteString(fmt.Sprintf(
        //    "[CMD] %s\nEXIT CODE: %d\nSTDOUT: %s\nSTDERR: %s\n\n",
        //    step.Cmd, result.ExitCode, result.Stdout, result.Stderr,
        //))

        if result.ExitCode != 0 {
            //showErrorDialog("å‘½ä»¤æ‰§è¡Œå¤±è´¥",
            //    fmt.Sprintf("å‘½ä»¤: %s\né€€å‡ºç : %d\nè¾“å‡º:\n%s\né”™è¯¯:\n%s",
            //        step.Cmd, result.ExitCode, result.Stdout, result.Stderr))
            return fmt.Errorf("å‘½ä»¤ %s å¤±è´¥ (é€€å‡ºç %d)", step.Cmd, result.ExitCode)
        }
    }
    
    return nil
}

func showInfoDialog(title, message string) {
    dialog.ShowCustom(
        title,
        "å…³é—­",
        container.NewVBox(
            widget.NewLabel(message),
            widget.NewIcon(theme.ConfirmIcon()),
        ),
        projectionWindow,
    )
}

func showErrorDialog(title, message string) {
    dialog.ShowCustom(
        title,
        "å…³é—­",
        container.NewVBox(
            widget.NewLabel(message),
            widget.NewIcon(theme.ErrorIcon()),
        ),
        projectionWindow,
    )
}

func showError(msg string) {
    //Edialog = widget.NewModalPopUp(
    //    container.NewHBox(
    //        widget.NewLabel("é”™è¯¯ä¿¡æ¯:"),
    //        widget.NewLabel(msg),
    //        widget.NewButton("å…³é—­", func() { Edialog.Hide() }),
    //    ),
    //    mainWindow.Canvas(),
    //)
    Edialog := dialog.NewError(fmt.Errorf(msg), projectionWindow)
    Edialog.Show()
}

func main() {
    var name string
    
	ipaddr := flag.String("ip", "127.0.0.1", "è®¾å¤‡IPåœ°å€")
    port := flag.Int("port", 9083, "æ§åˆ¶ç«¯å£")
    uploadPort := flag.Int("uploadPort", 9082, "ä¸Šä¼ APIç«¯å£") // æ–°å¢ä¸Šä¼ ç«¯å£
    containerID := flag.String("containerID", "", "Dockerå®¹å™¨ID")
    width := flag.Int("width", 720, "å®½åº¦") // æ–°å¢ä¸Šä¼ ç«¯å£
    height := flag.Int("height", 1280, "é«˜åº¦") // æ–°å¢ä¸Šä¼ ç«¯å£
    bakport := flag.Int("bakport", 0, "é«˜åº¦") // æ–°å¢ä¸Šä¼ ç«¯å£
    flag.StringVar(&name, "name", "åç§°", "name")

	flag.Parse()

	if ipaddr == nil || port == nil || uploadPort == nil || len(*ipaddr) == 0 || *port <= 0 || *uploadPort <= 0 || *containerID == "" {
		fmt.Println("ç¼ºå°‘å¿…è¦å‚æ•°ï¼šip, port, uploadPort, containerID")
		return
	}

	myApp := app.New()

	// åˆ›å»ºæ–°çª—å£
	projectionWindow = myApp.NewWindow("æŠ•å±" + *ipaddr + " - " + name)
	projectionImg = canvas.NewImageFromImage(generateDummyImage(270,480))
	projectionImg.FillMode = canvas.ImageFillStretch
	interactiveImg = NewInteractiveImage(projectionImg)
	interactiveImg.FillMode = canvas.ImageFillStretch

	// åˆå§‹åŒ–è§¦æ‘¸ä¼šè¯
    session := NewTouchSession(*height, *width) // æ³¨æ„å®é™…åˆ†è¾¨ç‡ä¸æ—‹è½¬æ–¹å‘

    // è·å–ç«¯å£å¹¶è¿æ¥
    //session.handle = sdkHandle
    err := session.checkHandle(*ipaddr, *port, *bakport)
    if err != nil {
		showError("è¿æ¥å¤±è´¥")
		return
    }
	
	// ç»‘å®šäº‹ä»¶å¤„ç†
    setupInputHandlers(interactiveImg, session)
	
	stopChan := make(chan struct{})
	var wg sync.WaitGroup
	wg.Add(1)
	
	// åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾
    if err := initAudio(); err != nil {
        fmt.Println("æ— æ³•åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾:", err)
        return
    }
	
	// å¯åŠ¨è§†é¢‘æµ
	startVideoStream(C.long(session.handle), 1280, 720, 2000)

	go decodeAndDisplayVideo(projectionImg, stopChan, &wg)

	main_content := container.NewMax(interactiveImg)
	// åˆ›å»ºå³ä¾§åŠŸèƒ½æ 
    funcPanel := container.NewHBox(
        widget.NewButton("ğŸ”Š+", func() {
            C.keyPress(session.handle, 24)
        }),
        widget.NewButton("ğŸ”Š-", func() {
            C.keyPress(session.handle, 25)
        }),
        widget.NewButton("ğŸ ", func() {
            C.keyPress(session.handle, 3)
        }),
        widget.NewButton("â†©", func() {
            C.keyPress(session.handle, 4)
        }),
    )

    // ä¿®æ”¹ç•Œé¢å¸ƒå±€
    mainContent := container.NewBorder(
        nil, funcPanel, nil, nil, // åº•éƒ¨æ”¾ç½®åŠŸèƒ½æ 
        main_content,
    )
	
	//newWidth := float32(0);
	// åˆ›å»ºå°ºå¯¸ç›‘å¬ç»„ä»¶
    sizeWatcher := NewSizeWatcher(func(size fyne.Size) {
        session.lock.Lock()
		
		// è·å–åŸå§‹å¤§å°ç”¨æ¥è®¡ç®—å›¾åƒéšçª—å£ç­‰æ¯”ç¼©æ”¾å¹¶ç»´æŒåœ¨çª—å£ä¸­é—´
		orgWidth := float64(projectionImg.Image.Bounds().Dx())
		orgHeight := float64(projectionImg.Image.Bounds().Dy())
		
		// è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
		scale := math.Min(
			float64(size.Width)/orgWidth,
			float64(size.Height)/orgHeight,
		)

		// è®¡ç®—å®é™…æ˜¾ç¤ºå°ºå¯¸å’Œä½ç½®
		newWidth := float32(orgWidth * scale)
		newHeight := float32(orgHeight * scale)
		
		//fmt.Println("1å¤§å°æ”¹å˜", newWidth, newHeight, size)
		interactiveImg.Resize(fyne.NewSize(newWidth, newHeight))
		main_content.Move(fyne.NewPos(size.Width/2-(newWidth/2), 0))
		interactiveImg.Refresh()
        session.windowSize = fyne.NewSize(newWidth, newHeight)
        session.lock.Unlock()
    })

	// ç»„åˆå®¹å™¨
    content := container.NewStack(
        mainContent,
        sizeWatcher,
    )

	// çª—å£å…³é—­æ—¶æ¸…ç†
	projectionWindow.SetOnClosed(func() {
		close(stopChan)
		wg.Wait()
		closeDevice(C.long(session.handle))
		session.handle = 0
		<-videoStreamChan
		C.stop_audio_processing()
	})
	
	// æŒ‰é”®è¾“å…¥
	projectionWindow.Canvas().SetOnTypedKey(func(ev *fyne.KeyEvent) {
		//fmt.Println("æŒ‰é”®è¾“å…¥", ev.Name)
		// å¤„ç†åŠŸèƒ½é”®
		switch ev.Name {
		case fyne.KeyReturn:
			C.keyPress(session.handle, 66)
		case fyne.KeyBackspace:
			C.keyPress(session.handle, 67)
		case fyne.KeyDelete:
			C.keyPress(session.handle, 112)
		case fyne.KeyLeft:
			C.keyPress(session.handle, 21) // KEYCODE_DPAD_LEFT
		case fyne.KeyRight:
			C.keyPress(session.handle, 22) // KEYCODE_DPAD_RIGHT
		// å¯æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šæŒ‰é”®æ˜ å°„
		}
	})

	projectionWindow.Canvas().SetOnTypedRune(func(r rune) {
		// å¤„ç†å­—ç¬¦è¾“å…¥
		cstr := C.CString(string(r))
		//fmt.Println("æ–‡æœ¬è¾“å…¥", cstr)
		defer C.free(unsafe.Pointer(cstr))
		C.sendText(session.handle, cstr)
	})
	
	// æ–‡ä»¶ä¸Šä¼ 
	projectionWindow.SetOnDropped(func(pos fyne.Position, uris []fyne.URI) {
		go func() { // å¼‚æ­¥å¤„ç†é˜²æ­¢ç•Œé¢å¡é¡¿
			if len(uris) == 0 {
				return
			}

			// æ˜¾ç¤ºä¸Šä¼ æç¤º
			uploadIndicator := canvas.NewText("ä¸Šä¼ ä¸­...", color.White)
			uploadIndicator.Move(fyne.NewPos(10, 10))
			//projectionWindow.Canvas().Add(uploadIndicator)
			//defer projectionWindow.Canvas().Remove(uploadIndicator)

			for _, uri := range uris {
				filePath := uri.Path()
				// è½¬æ¢Windowsè·¯å¾„æ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
				cleanPath := strings.Replace(filePath, "file://", "", 1)
				cleanPath = strings.Replace(cleanPath, "%20", " ", -1)

				// Windowsç³»ç»Ÿéœ€è¦ç‰¹æ®Šå¤„ç†
				if runtime.GOOS == "windows" {
					filePath = strings.TrimPrefix(cleanPath, "/")
					filePath = strings.Replace(cleanPath, "/", "\\", -1)
				}

				if strings.ToLower(filepath.Ext(filePath)) == ".apk" {
					// APKå®‰è£…æµç¨‹
					err := handleAPKInstall(
						*ipaddr, 
						*uploadPort,
						*containerID,
						2375,
						filePath,
					)
					if err != nil {
						showErrorDialog("å®‰è£…å¤±è´¥", err.Error())
					} else {
						showInfoDialog("å®‰è£…æˆåŠŸ", filepath.Base(cleanPath))
					}
					// [é”™è¯¯å¤„ç†...]
				} else {
					// è°ƒç”¨ä¸Šä¼ å‡½æ•°
					err := uploadFile(*ipaddr, *uploadPort, filePath)
					if err != nil {
						showErrorDialog("ä¸Šä¼ å¤±è´¥", err.Error())
					} else {
						showInfoDialog("ä¸Šä¼ æˆåŠŸï¼š/sdcard/upload/", filepath.Base(cleanPath))
					}
				}
			}
		}()
	})
	
	projectionWindow.SetContent(content)
	//projectionWindow.SetContent(container.NewScroll(projectionImg))
	projectionWindow.Resize(fyne.NewSize(540, 960))
	projectionWindow.ShowAndRun()
}
